{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T16:29:17.601659Z",
     "start_time": "2020-08-30T16:29:13.456187Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "\n",
    "\n",
    "EPOCHS     = 200\n",
    "BATCH_SIZE = 1000\n",
    "VERBOSE    = 1\n",
    "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()#tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "O = 'Berlin'\n",
    "\n",
    "def get_data():\n",
    "    print(f\"Loading raw data for {O}.\")\n",
    "    FILENAME =  f\"/Users/sonat/Documents/DataSets/Spatial/{O}_maps_labels.npz\"\n",
    "    data     = np.load(FILENAME)\n",
    "    labels   = data['labels']\n",
    "    data     = data[\"maps\"]\n",
    "    \n",
    "    print(f\"Loaded a dataset with {data.shape} and {labels.shape[0]} labels\")\n",
    "    return data, labels\n",
    "def flatten(data):\n",
    "    print('Flattening data')\n",
    "    print(f\"Old size:{data.shape}\")\n",
    "    data = data.reshape((data.shape[0],data.shape[1]*data.shape[2]))\n",
    "    print(f\"New size:{data.shape}\")\n",
    "    return data\n",
    "\n",
    "def normalize(data):\n",
    "    print(\"Normalizing data\")\n",
    "    data = data / np.std(data,axis=0)\n",
    "    if not np.any(np.isclose(np.std(data,axis=0),1)):\n",
    "        sys.exit('Normalization didn''t work')\n",
    "    return data\n",
    "\n",
    "def center(data):\n",
    "    print(\"Centering data\")\n",
    "    data = data - np.mean(data,axis=0)\n",
    "    if not np.any(np.isclose(np.mean(data,axis=0),0)):\n",
    "        sys.exit('Centering didn''t work')\n",
    "    return data\n",
    "\n",
    "def take_most_active(data):\n",
    "    return data\n",
    " \n",
    "    \n",
    "def splitter(data,labels):\n",
    "\n",
    "    print('Splitter called.')\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(data,labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    TRAIN_SAMPLES = X_train.shape[0]\n",
    "    TEST_SAMPLES  = X_test.shape[0]\n",
    "    \n",
    "    # cast\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    # One-hot representation of the labels.\n",
    "    NB_CLASSES     = np.unique(Y_train).shape[0]\n",
    "    print(NB_CLASSES)\n",
    "    Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
    "    Y_test  = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "def two_hidden_layer(data, labels,activation,N_HIDDEN=16):\n",
    "    INPUT_SHAPE = (data.shape[1],)\n",
    "    NB_CLASSES     = np.unique(labels).shape[0]\n",
    "    print(f\"Building Network with 2 hidden layers alike\")\n",
    "    print(f\"Found {NB_CLASSES} classes\")\n",
    "    print(f\"Found {INPUT_SHAPE} input size\")\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Dense(N_HIDDEN,input_shape=INPUT_SHAPE,name='dense_layer', activation='relu'))\n",
    "    model.add(keras.layers.Dense(N_HIDDEN,name='dense_layer_2', activation='relu'))\n",
    "    model.add(keras.layers.Dense(NB_CLASSES,name='linear', activation=activation))    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def logistic(data, labels,activation):\n",
    "    INPUT_SHAPE = (data.shape[1],)\n",
    "    NB_CLASSES     = np.unique(labels).shape[0]\n",
    "    print(f\"Building model Logistic Network alike\")\n",
    "    print(f\"Found {NB_CLASSES} classes\")\n",
    "    print(f\"Found {INPUT_SHAPE} input size\")\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Dense(NB_CLASSES,\n",
    "                                 input_shape=INPUT_SHAPE,\n",
    "                                 name='dense_layer', \n",
    "                                 activation=activation))\n",
    "    \n",
    "    return model\n",
    "\n",
    "pipeline = { \n",
    "#             0: #one-layer, ie logistric regression\n",
    "#                   {'data_loader'  : get_data,         \n",
    "#                    'preprocessors': [flatten, normalize],\n",
    "#                    'splitter'     : splitter,\n",
    "#                    'model'        : logistic,\n",
    "#                    'model_args'   : {'activation':'sigmoid'}\n",
    "#                 },\n",
    "#             1: #one-layer, ie logistric regression\n",
    "#                   {'data_loader'  : get_data,         \n",
    "#                    'preprocessors': [flatten, normalize],\n",
    "#                    'splitter'     : splitter,\n",
    "#                    'model'        : logistic,\n",
    "#                    'model_args'   : {'activation':'softmax'}\n",
    "#                 },\n",
    "#             2: #one-layer, ie logistric regression\n",
    "#                   {'data_loader'  : get_data,\n",
    "#                    'preprocessors': [flatten, normalize],\n",
    "#                    'splitter'     : splitter,\n",
    "#                    'model'        : two_hidden_layer,\n",
    "#                    'model_args'   : {'activation':'softmax','N_HIDDEN':16}\n",
    "#                 },\n",
    "#             3: #one-layer, ie logistric regression\n",
    "#                   {'data_loader'  : get_data,\n",
    "#                    'preprocessors': [flatten, normalize],\n",
    "#                    'splitter'     : splitter,\n",
    "#                    'model'        : two_hidden_layer,\n",
    "#                    'model_args'   : {'activation':'softmax','N_HIDDEN':64}\n",
    "#                 },\n",
    "#             4: #one-layer, ie logistric regression\n",
    "#                   {'data_loader'  : get_data,\n",
    "#                    'preprocessors': [flatten, normalize],\n",
    "#                    'splitter'     : splitter,\n",
    "#                    'model'        : two_hidden_layer,\n",
    "#                    'model_args'   : {'activation':'softmax','N_HIDDEN':8}\n",
    "#                 },\n",
    "#             5: #one-layer, ie logistric regression\n",
    "#                   {'data_loader'  : get_data,\n",
    "#                    'preprocessors': [flatten, normalize],\n",
    "#                    'splitter'     : splitter,\n",
    "#                    'model'        : two_hidden_layer,\n",
    "#                    'model_args'   : {'activation':'softmax','N_HIDDEN':64}\n",
    "#                 },\n",
    "            6: #one-layer, ie logistric regression\n",
    "                  {'data_loader'  : get_data,\n",
    "                   'preprocessors': [flatten, center],\n",
    "                   'splitter'     : splitter,\n",
    "                   'model'        : two_hidden_layer,\n",
    "                   'model_args'   : {'activation':'sigmoid','N_HIDDEN':64}\n",
    "                }\n",
    "            }\n",
    "#                  {'model_fun':logistic,'data_fun': get_data,'preprocess_fun': preprop}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-30T16:29:39.935799Z",
     "start_time": "2020-08-30T16:29:17.603032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabled dumping callback in thread MainThread (dump root: /tmp/tfdbg2_logdir, tensor debug mode: FULL_HEALTH)\n",
      "Loading raw data for Berlin.\n",
      "Loaded a dataset with (21980, 30, 30) and 21980 labels\n",
      "Flattening data\n",
      "Old size:(21980, 30, 30)\n",
      "New size:(21980, 900)\n",
      "Centering data\n",
      "Splitter called.\n",
      "17584 train samples\n",
      "4396 test samples\n",
      "7\n",
      "Building Network with 2 hidden layers alike\n",
      "Found 7 classes\n",
      "Found (900,) input size\n",
      "WARNING:tensorflow:Failed to read source code from path: /Users/sonat/Documents/repos/tf_tutorials/<ipython-input-2-500a566dc3fd>. Reason: Source path neither exists nor can be loaded as a .par file: /Users/sonat/Documents/repos/tf_tutorials/<ipython-input-2-500a566dc3fd>\n",
      "WARNING:tensorflow:Failed to read source code from path: /Users/sonat/Documents/repos/tf_tutorials/<ipython-input-1-2d7f0c986411>. Reason: Source path neither exists nor can be loaded as a .par file: /Users/sonat/Documents/repos/tf_tutorials/<ipython-input-1-2d7f0c986411>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_layer (Dense)          (None, 64)                57664     \n",
      "_________________________________________________________________\n",
      "dense_layer_2 (Dense)        (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "linear (Dense)               (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 62,279\n",
      "Trainable params: 62,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 1.9756 - accuracy: 0.1520WARNING:tensorflow:From /Users/sonat/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      " 2/15 [===>..........................] - ETA: 0s - loss: 1.9757 - accuracy: 0.1500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0644s). Check your callbacks.\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 1.9425 - accuracy: 0.1686 - val_loss: 1.8995 - val_accuracy: 0.1985\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.8585 - accuracy: 0.2292 - val_loss: 1.8543 - val_accuracy: 0.2249\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 1.7903 - accuracy: 0.2635 - val_loss: 1.8150 - val_accuracy: 0.2448\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 1.7224 - accuracy: 0.3013 - val_loss: 1.7804 - val_accuracy: 0.2602\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 1.6488 - accuracy: 0.3355 - val_loss: 1.7502 - val_accuracy: 0.2914\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 1.5679 - accuracy: 0.3697 - val_loss: 1.7310 - val_accuracy: 0.2949\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 1.4887 - accuracy: 0.4048 - val_loss: 1.7297 - val_accuracy: 0.3133\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 1.4150 - accuracy: 0.4432 - val_loss: 1.7353 - val_accuracy: 0.3216\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 1.3523 - accuracy: 0.4691 - val_loss: 1.7462 - val_accuracy: 0.3267\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 1.2935 - accuracy: 0.4976 - val_loss: 1.7593 - val_accuracy: 0.3293\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 1.2411 - accuracy: 0.5246 - val_loss: 1.7904 - val_accuracy: 0.3310\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 1.1957 - accuracy: 0.5472 - val_loss: 1.8129 - val_accuracy: 0.3372\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 1.1493 - accuracy: 0.5679 - val_loss: 1.8403 - val_accuracy: 0.3378\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.1132 - accuracy: 0.5819 - val_loss: 1.8712 - val_accuracy: 0.3341\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 1.0750 - accuracy: 0.6007 - val_loss: 1.8960 - val_accuracy: 0.3347\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 1.0387 - accuracy: 0.6163 - val_loss: 1.9254 - val_accuracy: 0.3324\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 1.0142 - accuracy: 0.6291 - val_loss: 1.9518 - val_accuracy: 0.3307\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.9721 - accuracy: 0.6479 - val_loss: 1.9707 - val_accuracy: 0.3429\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.9409 - accuracy: 0.6628 - val_loss: 1.9953 - val_accuracy: 0.3361\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.9105 - accuracy: 0.6768 - val_loss: 2.0292 - val_accuracy: 0.3344\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.8782 - accuracy: 0.6933 - val_loss: 2.0693 - val_accuracy: 0.3349\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.8528 - accuracy: 0.7081 - val_loss: 2.1147 - val_accuracy: 0.3364\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.8195 - accuracy: 0.7172 - val_loss: 2.1569 - val_accuracy: 0.3304\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7939 - accuracy: 0.7304 - val_loss: 2.1966 - val_accuracy: 0.3361\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.7705 - accuracy: 0.7394 - val_loss: 2.2449 - val_accuracy: 0.3384\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.7394 - accuracy: 0.7535 - val_loss: 2.2762 - val_accuracy: 0.3290\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.7128 - accuracy: 0.7631 - val_loss: 2.3195 - val_accuracy: 0.3304\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6930 - accuracy: 0.7729 - val_loss: 2.3760 - val_accuracy: 0.3273\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.6698 - accuracy: 0.7843 - val_loss: 2.4097 - val_accuracy: 0.3307\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6400 - accuracy: 0.7959 - val_loss: 2.4447 - val_accuracy: 0.3224\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.6186 - accuracy: 0.8054 - val_loss: 2.4878 - val_accuracy: 0.3298\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5924 - accuracy: 0.8160 - val_loss: 2.5288 - val_accuracy: 0.3284\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.5696 - accuracy: 0.8263 - val_loss: 2.5947 - val_accuracy: 0.3264\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.5544 - accuracy: 0.8322 - val_loss: 2.6385 - val_accuracy: 0.3185\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.5337 - accuracy: 0.8397 - val_loss: 2.6817 - val_accuracy: 0.3196\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.5130 - accuracy: 0.8484 - val_loss: 2.7295 - val_accuracy: 0.3261\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.4941 - accuracy: 0.8511 - val_loss: 2.7924 - val_accuracy: 0.3207\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4791 - accuracy: 0.8602 - val_loss: 2.8279 - val_accuracy: 0.3227\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4543 - accuracy: 0.8681 - val_loss: 2.8834 - val_accuracy: 0.3227\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.4449 - accuracy: 0.8714 - val_loss: 2.9405 - val_accuracy: 0.3133\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.4180 - accuracy: 0.8879 - val_loss: 2.9941 - val_accuracy: 0.3165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.4078 - accuracy: 0.8875 - val_loss: 3.0306 - val_accuracy: 0.3210\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.3902 - accuracy: 0.8957 - val_loss: 3.0917 - val_accuracy: 0.3167\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3744 - accuracy: 0.9010 - val_loss: 3.1313 - val_accuracy: 0.3139\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.3597 - accuracy: 0.9050 - val_loss: 3.2012 - val_accuracy: 0.3102\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3507 - accuracy: 0.9070 - val_loss: 3.2341 - val_accuracy: 0.3148\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3328 - accuracy: 0.9169 - val_loss: 3.2894 - val_accuracy: 0.3145\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.3206 - accuracy: 0.9205 - val_loss: 3.3280 - val_accuracy: 0.3153\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3077 - accuracy: 0.9237 - val_loss: 3.3856 - val_accuracy: 0.3145\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2962 - accuracy: 0.9268 - val_loss: 3.4414 - val_accuracy: 0.3119\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.2851 - accuracy: 0.9295 - val_loss: 3.5075 - val_accuracy: 0.3042\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.3071 - accuracy: 0.9229 - val_loss: 3.5425 - val_accuracy: 0.3173\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.3016 - accuracy: 0.9194 - val_loss: 3.5684 - val_accuracy: 0.3125\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.3042 - accuracy: 0.9226 - val_loss: 3.6343 - val_accuracy: 0.3119\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.2945 - accuracy: 0.9237 - val_loss: 3.6633 - val_accuracy: 0.3119\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.2599 - accuracy: 0.9407 - val_loss: 3.7008 - val_accuracy: 0.3119\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2515 - accuracy: 0.9399 - val_loss: 3.7639 - val_accuracy: 0.3079\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 15ms/step - loss: 0.2317 - accuracy: 0.9473 - val_loss: 3.7862 - val_accuracy: 0.3113\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.2161 - accuracy: 0.9527 - val_loss: 3.8229 - val_accuracy: 0.3108\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.2057 - accuracy: 0.9556 - val_loss: 3.8716 - val_accuracy: 0.3094\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1989 - accuracy: 0.9578 - val_loss: 3.8962 - val_accuracy: 0.3142\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1928 - accuracy: 0.9595 - val_loss: 4.0023 - val_accuracy: 0.3011\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1959 - accuracy: 0.9556 - val_loss: 3.9917 - val_accuracy: 0.3096\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1788 - accuracy: 0.9624 - val_loss: 4.0411 - val_accuracy: 0.3079\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1719 - accuracy: 0.9642 - val_loss: 4.0887 - val_accuracy: 0.3094\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.1631 - accuracy: 0.9679 - val_loss: 4.1139 - val_accuracy: 0.3102\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1595 - accuracy: 0.9678 - val_loss: 4.1928 - val_accuracy: 0.3071\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 17ms/step - loss: 0.1570 - accuracy: 0.9675 - val_loss: 4.2070 - val_accuracy: 0.3068\n",
      "Epoch 69/200\n",
      "10/15 [===================>..........] - ETA: 0s - loss: 0.1509 - accuracy: 0.9686"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: dense_layer/kernel_0 [Op:WriteHistogramSummary]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-500a566dc3fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m               callbacks=[tensorboard_callback])\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   2232\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m             \u001b[0mweight_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weight_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, tensor, family, step)\u001b[0m\n\u001b[1;32m    834\u001b[0m         name=scope)\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msummary_writer_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36msummary_writer_function\u001b[0;34m(name, tensor, function, family)\u001b[0m\n\u001b[1;32m    763\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     op = smart_cond.smart_cond(\n\u001b[0;32m--> 765\u001b[0;31m         should_record_summaries(), record, _nothing, name=\"\")\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m    756\u001b[0m     with ops.name_scope(name_scope), summary_op_util.summary_scope(\n\u001b[1;32m    757\u001b[0m         name, family, values=[tensor]) as (tag, scope):\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(tag, scope)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         name=scope)\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msummary_writer_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mwrite_histogram_summary\u001b[0;34m(writer, step, tag, values, name)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m       return write_histogram_summary_eager_fallback(\n\u001b[0;32m--> 480\u001b[0;31m           writer, step, tag, values, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mwrite_histogram_summary_eager_fallback\u001b[0;34m(writer, step, tag, values, name, ctx)\u001b[0m\n\u001b[1;32m    497\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m   _result = _execute.execute(b\"WriteHistogramSummary\", 0, inputs=_inputs_flat,\n\u001b[0;32m--> 499\u001b[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m    500\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mexecute_with_callbacks\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_with_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m\"\"\"Monkey-patch to execute to enable execution callbacks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquick_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/repos/tf_tutorials/.env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: dense_layer/kernel_0 [Op:WriteHistogramSummary]"
     ]
    }
   ],
   "source": [
    "!rm -rf /tmp/tfdbg2_logdir\n",
    "tf.debugging.experimental.enable_dump_debug_info('/tmp/tfdbg2_logdir', tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "#run the pipeline:\n",
    "for i in pipeline.keys():\n",
    "    data,labels = pipeline[i]['data_loader']()\n",
    "\n",
    "    for p_fun in pipeline[i]['preprocessors']:\n",
    "        data = p_fun(data)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = pipeline[i]['splitter'](data,labels)\n",
    "    \n",
    "    kwargs  = pipeline[i]['model_args']\n",
    "    model = pipeline[i]['model'](data,labels,**kwargs)\n",
    "\n",
    "    # Compiling the model.\n",
    "    model.compile(optimizer=OPTIMIZER,\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    log_dir = \"/tmp/tfdbg2_logdir/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Training the model.\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=BATCH_SIZE, \n",
    "              epochs=EPOCHS,\n",
    "              verbose=VERBOSE, \n",
    "              validation_split=VALIDATION_SPLIT,\n",
    "              callbacks=[tensorboard_callback])\n",
    "\n",
    "    #evaluate the model\n",
    "    test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "    print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
